{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1h4AXPXuajaoux77rLuW56kkpkHqBqW7c",
      "authorship_tag": "ABX9TyNMC3/EMfveZdpZVS7MJFGR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manuja001/DL_Lab_03/blob/main/Lab_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wmqfCX87nBY",
        "outputId": "29c582f7-891b-4b39-cdf6-53e3dd91fcb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/DL Lab 03\n"
          ]
        }
      ],
      "source": [
        "cd \"/content/drive/MyDrive/Colab Notebooks/DL Lab 03\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprting the Zip file and extracting all\n",
        "import zipfile\n",
        "with zipfile.ZipFile('weights.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('weights')"
      ],
      "metadata": {
        "id": "MTY-K93Y74ul"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "cwd = os.getcwd()\n",
        "print(cwd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fnm1Y9tT8tDX",
        "outputId": "8209985e-9b5d-47d3-b828-1a83f816ec62"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/DL Lab 03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os\n",
        "utils_dir = \"/\"\n",
        "assert os.path.exists(utils_dir), \"folder path is worng\"\n",
        "sys.path.append(utils_dir)"
      ],
      "metadata": {
        "id": "pykW8C1r8WKY"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from keras.models import Model\n",
        "# from keras.layers.normalization import BatchNormalization\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "#from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
        "# from keras.layers.merge import Concatenate\n",
        "from tensorflow.keras.layers import concatenate\n",
        "\n",
        "from tensorflow.keras.layers import Lambda, Flatten, Dense\n",
        "from keras.initializers import glorot_uniform\n",
        "# from keras.engine.topology import Layer\n",
        "from tensorflow.keras.layers import Layer, InputSpec\n",
        "from keras import backend as K\n",
        "K.set_image_data_format('channels_first')\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from fr_utils import *\n",
        "from inception_blocks_v2 import *\n",
        "\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)\n",
        "\n",
        "# np.set_printoptions(threshold=np.nan)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdqaTjOJOi66",
        "outputId": "42e2cb34-93a8-46d2-911a-c2574e4c67c7"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n",
            "2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FRmodel = faceRecoModel(input_shape=(3, 96, 96))"
      ],
      "metadata": {
        "id": "YQnhLA1UA9NA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Params:\", FRmodel.count_params())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9OG_qT7BA-M",
        "outputId": "dedd2033-b628-434b-a4ed-33419c90c595"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Params: 3743280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: triplet_loss\n",
        "\n",
        "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
        "    \"\"\"\n",
        "    Implementation of the triplet loss as defined by formula (3)\n",
        "\n",
        "    Arguments:\n",
        "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
        "    y_pred -- python list containing three objects:\n",
        "            anchor -- the encodings for the anchor images, of shape (None, 128)\n",
        "            positive -- the encodings for the positive images, of shape (None, 128)\n",
        "            negative -- the encodings for the negative images, of shape (None, 128)\n",
        "\n",
        "    Returns:\n",
        "    loss -- real number, value of the loss\n",
        "    \"\"\"\n",
        "\n",
        "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
        "\n",
        "    ### START CODE HERE ### (≈ 4 lines)\n",
        "    # Step 1: Compute the (encoding) distance between the anchor and the positive\n",
        "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)))\n",
        "    # Step 2: Compute the (encoding) distance between the anchor and the negative\n",
        "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)))\n",
        "    # Step 3: subtract the two previous distances and add alpha.\n",
        "    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)\n",
        "    # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.\n",
        "    loss = tf.maximum(tf.reduce_mean(basic_loss), 0.0)\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "56g6V_AnDqoT"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with tf.Session() as test:\n",
        "with tf.compat.v1.Session() as test:\n",
        "#    tf.set_random_seed(1)\n",
        "    tf.random.set_seed(1)\n",
        "    y_true = (None, None, None)\n",
        "    y_pred = (tf.random.normal([3, 128], mean=6, stddev=0.1, seed = 1),\n",
        "              tf.random.normal([3, 128], mean=1, stddev=1, seed = 1),\n",
        "              tf.random.normal([3, 128], mean=3, stddev=4, seed = 1))\n",
        "    loss = triplet_loss(y_true, y_pred)\n",
        "\n",
        "    print(\"loss = \" + str(loss.eval()))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnFYKibEDuyL",
        "outputId": "84d4308f-8ad8-4be1-895c-e77804882ef1"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss = 350.02637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
        "load_weights_from_FaceNet(FRmodel)"
      ],
      "metadata": {
        "id": "Zj4tOMIwD-S_"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "cwd = os.getcwd()\n",
        "print(cwd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5HZ5xdUPCti",
        "outputId": "73401e8e-237d-47e9-9a03-c41478e593e8"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/DL Lab 03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "database = {}\n",
        "database[\"danielle\"] = img_to_encoding(\"danielle.png\", FRmodel)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fjA8SPtCE_yF",
        "outputId": "b89d1b1b-c49b-4a72-fb50-108c4fd54f32"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnimplementedError",
          "evalue": "Graph execution error:\n\nDetected at node FaceRecoModel_1/conv1_1/convolution defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipython-input-3347962154.py\", line 2, in <cell line: 0>\n\n  File \"/content/drive/MyDrive/Colab Notebooks/DL Lab 03/fr_utils.py\", line 277, in img_to_encoding\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 635, in predict_on_batch\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 260, in one_step_on_data_distributed\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 250, in one_step_on_data\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 105, in predict_step\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\", line 936, in __call__\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\", line 58, in __call__\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\", line 183, in call\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/function.py\", line 177, in _run_through_graph\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\", line 648, in call\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\", line 936, in __call__\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\", line 58, in __call__\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py\", line 250, in call\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py\", line 240, in convolution_op\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py\", line 1342, in conv\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/nn.py\", line 340, in conv\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/nn.py\", line 313, in _conv\n\nThe Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW\n\t [[{{node FaceRecoModel_1/conv1_1/convolution}}]] [Op:__inference_one_step_on_data_distributed_12559]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3347962154.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdatabase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdatabase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"danielle\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"danielle.png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFRmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/drive/MyDrive/Colab Notebooks/DL Lab 03/fr_utils.py\u001b[0m in \u001b[0;36mimg_to_encoding\u001b[0;34m(image_path, model)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m     \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    633\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m         batch_outputs = tree.map_structure(\n\u001b[1;32m    637\u001b[0m             \u001b[0mconvert_to_np_if_not_ragged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node FaceRecoModel_1/conv1_1/convolution defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipython-input-3347962154.py\", line 2, in <cell line: 0>\n\n  File \"/content/drive/MyDrive/Colab Notebooks/DL Lab 03/fr_utils.py\", line 277, in img_to_encoding\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 635, in predict_on_batch\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 260, in one_step_on_data_distributed\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 250, in one_step_on_data\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 105, in predict_step\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\", line 936, in __call__\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\", line 58, in __call__\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\", line 183, in call\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/function.py\", line 177, in _run_through_graph\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\", line 648, in call\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\", line 936, in __call__\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\", line 58, in __call__\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py\", line 250, in call\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py\", line 240, in convolution_op\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py\", line 1342, in conv\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/nn.py\", line 340, in conv\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/nn.py\", line 313, in _conv\n\nThe Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW\n\t [[{{node FaceRecoModel_1/conv1_1/convolution}}]] [Op:__inference_one_step_on_data_distributed_12559]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "R_WTlhEmQ1zZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: verify\n",
        "\n",
        "def verify(image_path, identity, database, model):\n",
        "    \"\"\"\n",
        "    Function that verifies if the person on the \"image_path\" image is \"identity\".\n",
        "\n",
        "    Arguments:\n",
        "    image_path -- path to an image\n",
        "    identity -- string, name of the person you'd like to verify the identity. Has to be a resident of the Happy house.\n",
        "    database -- python dictionary mapping names of allowed people's names (strings) to their encodings (vectors).\n",
        "    model -- your Inception model instance in Keras\n",
        "\n",
        "    Returns:\n",
        "    dist -- distance between the image_path and the image of \"identity\" in the database.\n",
        "    door_open -- True, if the door should open. False otherwise.\n",
        "    \"\"\"\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # Step 1: Compute the encoding for the image. Use img_to_encoding() see example above. (≈ 1 line)\n",
        "    encoding = img_to_encoding(image_path, model)\n",
        "\n",
        "    # Step 2: Compute distance with identity's image (≈ 1 line)\n",
        "    dist = np.linalg.norm(encoding-database[identity])\n",
        "\n",
        "    # Step 3: Open the door if dist < 0.7, else don't open (≈ 3 lines)\n",
        "    if dist < 0.7:\n",
        "        print(\"It's \" + str(identity) + \", welcome home!\")\n",
        "        door_open = True\n",
        "    else:\n",
        "        print(\"It's not \" + str(identity) + \", please go away\")\n",
        "        door_open = False\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return dist, door_open"
      ],
      "metadata": {
        "id": "sR3BNm8JFfXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verify(\"images/camera_0.jpg\", \"younes\", database, FRmodel)"
      ],
      "metadata": {
        "id": "SxVC8XFOFjdi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}